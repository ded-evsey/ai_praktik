{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evsee\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\evsee\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import ShuffleSplit, cross_val_score\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# считываем подготовленный датасет\n",
    "dataset = pd.read_csv('data/cleaned_data.csv', index_col=0).dropna()\n",
    "\n",
    "# массив n-граммных схем, которые будут использоваться в работе\n",
    "# например, (1, 3) означает униграммы + биграммы + триграммы\n",
    "ngram_schemes = [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram Scheme: (1, 1)\n",
      "Count Vectorizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evsee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: 0.7211656306485033\n",
      "Linear: 0.7167952504812708\n",
      "Linear Parameters: {'alpha': 0.0001, 'loss': 'hinge', 'penalty': 'l2'}\n",
      "\n",
      "TF-IDF Vectorizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evsee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: 0.7166042116710019\n",
      "Linear: 0.7246807447574541\n",
      "Linear Parameters: {'alpha': 1e-05, 'loss': 'hinge', 'penalty': 'l2'}\n",
      "\n",
      "N-gram Scheme: (1, 2)\n",
      "Count Vectorizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evsee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: 0.7364046495907359\n",
      "Linear: 0.7425972461020736\n",
      "Linear Parameters: {'alpha': 0.0001, 'loss': 'hinge', 'penalty': 'l2'}\n",
      "\n",
      "TF-IDF Vectorizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evsee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: 0.7395641376067246\n",
      "Linear: 0.7493335684580229\n",
      "Linear Parameters: {'alpha': 1e-06, 'loss': 'log', 'penalty': 'elasticnet'}\n",
      "\n",
      "N-gram Scheme: (1, 3)\n",
      "Count Vectorizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evsee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: 0.736263574776999\n",
      "Linear: 0.7489397346030067\n",
      "Linear Parameters: {'alpha': 1e-05, 'loss': 'log', 'penalty': 'l2'}\n",
      "\n",
      "TF-IDF Vectorizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evsee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: 0.7427265646813326\n",
      "Linear: 0.7524048847154257\n",
      "Linear Parameters: {'alpha': 1e-06, 'loss': 'log', 'penalty': 'elasticnet'}\n",
      "\n",
      "N-gram Scheme: (1, 4)\n",
      "Count Vectorizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evsee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: 0.7354318211876737\n",
      "Linear: 0.7502770062748901\n",
      "Linear Parameters: {'alpha': 1e-05, 'loss': 'log', 'penalty': 'l2'}\n",
      "\n",
      "TF-IDF Vectorizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evsee\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: 0.7442636923393438\n",
      "Linear: 0.7521403694396684\n",
      "Linear Parameters: {'alpha': 1e-06, 'loss': 'log', 'penalty': 'l2'}\n",
      "\n",
      "N-gram Scheme: (1, 5)\n",
      "Count Vectorizer\n"
     ]
    }
   ],
   "source": [
    "for ngram_scheme in ngram_schemes:\n",
    "\n",
    "\tprint('N-gram Scheme:', ngram_scheme)\n",
    "\n",
    "\tcount_vectorizer = CountVectorizer(analyzer = \"word\", ngram_range=ngram_scheme) \n",
    "\ttfidf_vectorizer = TfidfVectorizer(analyzer = \"word\", ngram_range=ngram_scheme)\n",
    "\n",
    "\tvectorizers = [count_vectorizer, tfidf_vectorizer]\n",
    "\tvectorizers_names = ['Count Vectorizer', 'TF-IDF Vectorizer']\n",
    "\n",
    "\tfor i in range(len(vectorizers)):\n",
    "\t\tprint(vectorizers_names[i])\n",
    "\t\tvectorizer = vectorizers[i]\n",
    "\n",
    "\t\tX = vectorizer.fit_transform(dataset['text'])\n",
    "\t\ty = dataset['label']\n",
    "\n",
    "\t\tcv = ShuffleSplit(len(y), n_iter=5, test_size=0.3, random_state=0)\n",
    "\n",
    "\t\t# наивный байес\n",
    "\t\tclf = MultinomialNB()\n",
    "\t\tNB_result = cross_val_score(clf, X, y, cv=cv).mean()\n",
    "\n",
    "\t\t# линейный классификатор\n",
    "\t\tclf = SGDClassifier()\n",
    "\n",
    "\t\tparameters = {\n",
    "\t\t    'loss': ('log', 'hinge'),\n",
    "\t\t    'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
    "\t\t    'alpha': [0.001, 0.0001, 0.00001, 0.000001]\n",
    "\t\t}\n",
    "\n",
    "\t\tgs_clf = GridSearchCV(clf, parameters, cv=cv, n_jobs=-1)\n",
    "\t\tgs_clf = gs_clf.fit(X, y)\n",
    "\n",
    "\t\tL_result = gs_clf.best_score_\n",
    "\n",
    "\t\tprint('NB:', NB_result.mean())\n",
    "\t\tprint('Linear:', L_result)\n",
    "\t\tprint('Linear Parameters:', gs_clf.best_params_)\n",
    "\t\tprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
